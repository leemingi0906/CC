import os
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
import numpy as np
import argparse
import cv2
import sys
import time
import gc

# [í™˜ê²½ ì„¤ì •] ì‹¤í–‰ ìœ„ì¹˜ ë° src í´ë”ë¥¼ ì‹œìŠ¤í…œ ê²½ë¡œì— ë“±ë¡
curr_path = os.getcwd()
src_path = os.path.join(curr_path, 'src')
for path in [curr_path, src_path]:
    if path not in sys.path:
        sys.path.insert(0, path)

# í”„ë¡œì íŠ¸ ë‚´ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from src.data_loader import MCNN_SHT_Dataset
    from src.models import MCNN
    from src.utils import save_results
except ImportError as e:
    print(f"âŒ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    sys.exit(1)

def test():
    parser = argparse.ArgumentParser(description='MCNN Test Script (Final Precision)')
    
    # 1. ê²½ë¡œ ì„¤ì •
    parser.add_argument('--data_path', default='./data/original/shanghaitech', help='Dataset root path')
    parser.add_argument('--dataset', default='B', choices=['A', 'B'], help='Dataset Part')
    parser.add_argument('--weight_path', required=True, help='Path to .pth weight file')
    
    # 2. ì¶œë ¥ ë° ì‹œê°í™” ì„¤ì •
    parser.add_argument('--output_dir', default='./output', help='Directory to save results')
    parser.add_argument('--save_vis', action='store_true', help='ì˜ˆì¸¡ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€')
    parser.add_argument('--gpu_id', default=0, type=int)
    
    args = parser.parse_args()
    device = torch.device(f"cuda:{args.gpu_id}" if torch.cuda.is_available() else "cpu")

    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir, exist_ok=True)

    # í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ ì ìš©
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    print(f"ğŸ“Š [Test] Loading ShanghaiTech Part {args.dataset}...")
    test_set = MCNN_SHT_Dataset(args.data_path, part=args.dataset, phase='test', transform=transform)
    test_loader = DataLoader(test_set, batch_size=1, shuffle=False, num_workers=2)

    # 2. ëª¨ë¸ ë¡œë“œ ë° ê°€ì¤‘ì¹˜ ë§¤í•‘
    model = MCNN().to(device)
    
    if os.path.exists(args.weight_path):
        # [ìˆ˜ì •] weights_only=Trueë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ì•ˆ ê²½ê³  í•´ê²°
        checkpoint = torch.load(args.weight_path, map_location=device, weights_only=True)
        state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint
        
        # module. ì ‘ë‘ì‚¬ ì œê±° (DataParallel ëŒ€ì‘)
        new_state_dict = {k[7:] if k.startswith('module.') else k: v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print(f"âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ: {args.weight_path}")
    else:
        print(f"âŒ ì˜¤ë¥˜: ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.weight_path}")
        return

    model.eval()

    mae, mse_sum = 0.0, 0.0
    print(f"ğŸ” Starting Inference on {len(test_set)} images...")

    start_time = time.time()
    with torch.no_grad():
        for i, (img, gt) in enumerate(test_loader):
            img, gt = img.to(device), gt.to(device)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            pred = model(img)
            
            # ì¹´ìš´íŠ¸ ê³„ì‚° (Density Map í”½ì…€ í•©)
            p_cnt = torch.sum(pred).item()
            g_cnt = torch.sum(gt).item()
            
            mae += abs(p_cnt - g_cnt)
            mse_sum += (p_cnt - g_cnt)**2

            # [ì‹œê°í™”] --save_vis ì˜µì…˜ ì‹œ 10ì¥ë§ˆë‹¤ ì €ì¥
            if args.save_vis and i % 10 == 0:
                save_results(img, gt, pred, args.output_dir, fname=f'test_sample_{i}.png')

    avg_mae = mae / len(test_set)
    avg_rmse = np.sqrt(mse_sum / len(test_set))
    total_time = time.time() - start_time

    # 3. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ ì‘ì„±
    result_text = f"""
========================================
ğŸ† MCNN Test Results (Part {args.dataset})
========================================
- Weight File: {os.path.abspath(args.weight_path)}
- Total Images: {len(test_set)}
- MAE (Accuracy): {avg_mae:.2f}
- RMSE (Robustness): {avg_rmse:.2f}
- Total Time: {total_time:.1f}s
- Avg Speed: {total_time/len(test_set):.4f}s per image
========================================
"""
    print(result_text)

    # ê²°ê³¼ ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
    model_name = os.path.basename(args.weight_path).split('.')[0]
    report_name = f'report_{args.dataset}_{model_name}.txt'
    with open(os.path.join(args.output_dir, report_name), 'w') as f:
        f.write(result_text)
    
    print(f"ğŸ’¾ ê²°ê³¼ê°€ {args.output_dir}/{report_name}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == '__main__':
    test()