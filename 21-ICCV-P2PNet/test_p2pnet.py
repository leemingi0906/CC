import argparse
import os
import torch
import sys
from torch.utils.data import DataLoader
import util.misc as utils
from models import build_model
import warnings
import time

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë¬´ì‹œ ë° í™˜ê²½ ì„¤ì •
warnings.filterwarnings('ignore')
sys.path.append(os.getcwd())

def get_args_parser():
    parser = argparse.ArgumentParser('P2PNet Test Set Evaluation Script', add_help=False)
    
    # 1. ëª¨ë¸ ë° ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •
    parser.add_argument('--backbone', default='vgg16_bn', type=str, help="Backbone ëª¨ë¸ ëª…")
    parser.add_argument('--row', default=2, type=int, help="ì•µì»¤ í¬ì¸íŠ¸ í–‰ ìˆ˜")
    parser.add_argument('--line', default=2, type=int, help="ì•µì»¤ í¬ì¸íŠ¸ ì—´ ìˆ˜")
    parser.add_argument('--dataset_file', default='SHHA', help='ë°ì´í„°ì…‹ ì¢…ë¥˜ (SHHA ë˜ëŠ” SHHB)')
    parser.add_argument('--data_root', default='/home/kimsooyeon/Downloads/SHT', help='ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ')
    parser.add_argument('--weight_path', default='', type=str, required=True, help='ê°€ì¤‘ì¹˜ íŒŒì¼(.pth) ê²½ë¡œ')
    parser.add_argument('--output_dir', default='./logs_test_result', help='ê²°ê³¼ ì €ì¥ í´ë”')
    parser.add_argument('--gpu_id', default=0, type=int, help='GPU ID')
    parser.add_argument('--num_workers', default=4, type=int)
    
    # build_model í˜¸í™˜ìš© ë”ë¯¸ ì¸ìë“¤
    parser.add_argument('--lr', default=1e-4, type=float)
    parser.add_argument('--lr_backbone', default=1e-5, type=float)
    parser.add_argument('--batch_size', default=1, type=int)
    parser.add_argument('--weight_decay', default=1e-4, type=float)
    parser.add_argument('--epochs', default=3500, type=int)
    parser.add_argument('--lr_drop', default=3500, type=int)
    parser.add_argument('--clip_max_norm', default=0.1, type=float)
    parser.add_argument('--frozen_weights', type=str, default=None)
    parser.add_argument('--set_cost_class', default=1, type=float)
    parser.add_argument('--set_cost_point', default=0.05, type=float)
    parser.add_argument('--point_loss_coef', default=0.0002, type=float)
    parser.add_argument('--eos_coef', default=0.5, type=float)

    return parser

def main(args):
    device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir, exist_ok=True)

    # 1. ëª¨ë¸ ë¹Œë“œ
    print(f"ğŸš€ [Step 1] ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘: {args.backbone}")
    res = build_model(args, training=False)
    model = res[0] if isinstance(res, tuple) else res
    model.to(device)

    # 2. ê°€ì¤‘ì¹˜ ë¡œë“œ ë° ì ‘ë‘ì‚¬(module.) ì²˜ë¦¬
    if os.path.exists(args.weight_path):
        print(f"ğŸ“‚ [Step 2] ê°€ì¤‘ì¹˜ ë¡œë“œ: {args.weight_path}")
        checkpoint = torch.load(args.weight_path, map_location='cpu')
        state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint
        
        # DataParallelë¡œ ì €ì¥ëœ ê²½ìš° 'module.' ì œê±° ë¡œì§
        new_state_dict = {k[7:] if k.startswith('module.') else k: v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print("âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ.")
    else:
        print(f"âŒ ì˜¤ë¥˜: ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.weight_path}")
        return

    # 3. ë°ì´í„° ë¡œë”© (ê°€ì¥ ì•ˆì „í•œ ìˆœì„œë¡œ ì‹œë„)
    print(f"ğŸ“Š [Step 3] ê³µì‹ í…ŒìŠ¤íŠ¸ì…‹(Test Set) êµ¬ì„± ì‹œë„: {args.dataset_file}")
    loading_data_fn = None
    
    # (1) ìš°ì„ ìˆœìœ„: crowd_datasets/loading_data.py ì§ì ‘ ì°¸ì¡°
    try:
        from crowd_datasets.loading_data import loading_data as loading_data_fn
        print(f"ğŸ” ì»¤ìŠ¤í…€ ë¡œë”(loading_data.py)ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    except ImportError:
        # (2) ëŒ€ë¹„ì±…: crowd_datasets íŒ¨í‚¤ì§€ì˜ build_dataset íŒ©í† ë¦¬ ì‹œë„
        print("âš ï¸ ì»¤ìŠ¤í…€ ë¡œë” íƒìƒ‰ ì‹¤íŒ¨. build_dataset ì‹œë„ ì¤‘...")
        try:
            from crowd_datasets import build_dataset
            loading_data_fn = build_dataset(args=args)
        except Exception as e:
            print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e})")
            return

    # ì‹¤ì œ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
    try:
        # loading_data_fnì´ (train, test) íŠœí”Œì„ ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸ í›„ í˜¸ì¶œ
        import inspect
        sig = inspect.signature(loading_data_fn)
        if 'args' in sig.parameters:
            _, test_set = loading_data_fn(args.data_root, args)
        else:
            _, test_set = loading_data_fn(args.data_root)
            
        print(f"âœ… {args.dataset_file} í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì™„ë£Œ (ì´ë¯¸ì§€ {len(test_set)}ì¥)")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    data_loader_test = DataLoader(
        test_set, 1, shuffle=False, num_workers=args.num_workers,
        collate_fn=utils.collate_fn_crowd
    )

    # 4. ì„±ëŠ¥ í‰ê°€ (Evaluation)
    print(f"ğŸ” [Step 4] ê³µì‹ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    model.eval()
    start_time = time.time()
    
    # engine.pyì—ì„œ í‰ê°€ ë¡œì§ ë¡œë“œ (Import ì—ëŸ¬ ë°©ì§€ìš©)
    try:
        from engine import evaluate_crowd_no_overlap
    except ImportError:
        print("âŒ ì˜¤ë¥˜: engine.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    with torch.no_grad():
        mae, mse = evaluate_crowd_no_overlap(model, data_loader_test, device)
    
    end_time = time.time()
    
    # 5. ê²°ê³¼ ë¦¬í¬íŠ¸
    result_text = f"""
========================================
ğŸ† {args.dataset_file} ê³µì‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼
========================================
- ê°€ì¤‘ì¹˜ íŒŒì¼: {args.weight_path}
- í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_set)}
- MAE (ì •í™•ë„): {mae:.2f}
- MSE (ê°•ê±´ì„±): {mse:.2f}
- ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}s
========================================
"""
    print(result_text)
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    res_path = os.path.join(args.output_dir, f"test_res_{args.dataset_file}.txt")
    with open(res_path, "w") as f:
        f.write(result_text)
    print(f"ğŸ’¾ ê²°ê³¼ ìš”ì•½ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {res_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser('P2PNet evaluation', parents=[get_args_parser()])
    args = parser.parse_args()
    main(args)