import argparse
import os
import torch
import sys
from torch.utils.data import DataLoader
import util.misc as utils
from models import build_model
from crowd_datasets import build_dataset
from engine import evaluate_crowd_no_overlap
import warnings
import time

# ë¶ˆí•„ìš”í•œ ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

def get_args_parser():
    parser = argparse.ArgumentParser('P2PNet Test Set Evaluation Script', add_help=False)
    
    # 1. ëª¨ë¸ êµ¬ì¡° ì„¤ì • (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
    parser.add_argument('--backbone', default='vgg16_bn', type=str, help="Backbone ëª¨ë¸ ëª…")
    parser.add_argument('--row', default=2, type=int, help="ì•µì»¤ í¬ì¸íŠ¸ í–‰ ìˆ˜")
    parser.add_argument('--line', default=2, type=int, help="ì•µì»¤ í¬ì¸íŠ¸ ì—´ ìˆ˜")
    
    # 2. ë°ì´í„°ì…‹ ë° ê²½ë¡œ ì„¤ì •
    parser.add_argument('--dataset_file', default='SHHA', help='ë°ì´í„°ì…‹ ì¢…ë¥˜ (SHHA ë˜ëŠ” SHHB)')
    parser.add_argument('--data_root', default='/home/kimsooyeon/Downloads/SHT', help='ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ')
    
    # 3. ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
    parser.add_argument('--weight_path', default='', type=str, required=True, help='ê°€ì¤‘ì¹˜ íŒŒì¼(.pth) ê²½ë¡œ')
    
    # 4. ê²°ê³¼ ì €ì¥ ë° í•˜ë“œì›¨ì–´ ì„¤ì •
    parser.add_argument('--output_dir', default='./logs_test_result', help='ê²°ê³¼ ì €ì¥ í´ë”')
    parser.add_argument('--gpu_id', default=0, type=int, help='GPU ID')
    parser.add_argument('--num_workers', default=4, type=int)
    
    # build_model í˜¸í™˜ìš© ë”ë¯¸ ì¸ì (í…ŒìŠ¤íŠ¸ ì‹œ ê°’ ë¬´ê´€)
    parser.add_argument('--lr', default=1e-4, type=float)
    parser.add_argument('--lr_backbone', default=1e-5, type=float)
    parser.add_argument('--batch_size', default=1, type=int)
    parser.add_argument('--weight_decay', default=1e-4, type=float)
    parser.add_argument('--epochs', default=3500, type=int)
    parser.add_argument('--lr_drop', default=3500, type=int)
    parser.add_argument('--clip_max_norm', default=0.1, type=float)
    parser.add_argument('--frozen_weights', type=str, default=None)
    parser.add_argument('--set_cost_class', default=1, type=float)
    parser.add_argument('--set_cost_point', default=0.05, type=float)
    parser.add_argument('--point_loss_coef', default=0.0002, type=float)
    parser.add_argument('--eos_coef', default=0.5, type=float)

    return parser

def main(args):
    # [í™˜ê²½ ì„¤ì •] í˜„ì¬ ê²½ë¡œë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ë“±ë¡í•˜ì—¬ ëª¨ë“ˆ íƒìƒ‰ ìš°ì„ ìˆœìœ„ í™•ë³´
    sys.path.append(os.getcwd())
    
    device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir, exist_ok=True)

    # 1. ëª¨ë¸ ë¹Œë“œ
    print(f"ğŸš€ [Step 1] ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘: {args.backbone}")
    res = build_model(args, training=False)
    model = res[0] if isinstance(res, tuple) else res
    model.to(device)

    # 2. ê°€ì¤‘ì¹˜ ë¡œë“œ
    if os.path.exists(args.weight_path):
        print(f"ğŸ“‚ [Step 2] ê°€ì¤‘ì¹˜ ë¡œë“œ: {args.weight_path}")
        checkpoint = torch.load(args.weight_path, map_location='cpu')
        state_dict = checkpoint['model'] if 'model' in checkpoint else checkpoint
        
        # DataParallel('module.') ì œê±°
        new_state_dict = {k[7:] if k.startswith('module.') else k: v for k, v in state_dict.items()}
        model.load_state_dict(new_state_dict)
        print("âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ.")
    else:
        print(f"âŒ ì˜¤ë¥˜: ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.weight_path}")
        return

    # 3. ê³µì‹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë”©
    print(f"ğŸ“Š [Step 3] ê³µì‹ í…ŒìŠ¤íŠ¸ì…‹(Test Set) êµ¬ì„± ì‹œë„: {args.dataset_file}")
    loading_data_fn = None
    
    try:
        from crowd_datasets.loading_data import loading_data as loading_data_fn
        print(f"ğŸ” ì»¤ìŠ¤í…€ ë¡œë”(loading_data.py)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    except ImportError:
        print("âš ï¸ ì»¤ìŠ¤í…€ ë¡œë”ê°€ ì—†ì–´ ê¸°ë³¸ Factory ë¹Œë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        try:
            loading_data_fn = build_dataset(args=args)
        except:
            print("âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: ë°ì´í„°ì…‹ ë¹Œë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

    # ì‹¤ì œ ë°ì´í„°ì…‹ ê°ì²´ ìƒì„±
    try:
        # loading_data_fnì€ (train_set, test_set) íŠœí”Œì„ ë°˜í™˜í•¨
        # ìš°ë¦¬ëŠ” ë‘ ë²ˆì§¸ ì¸ìì¸ ê³µì‹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©í•¨
        import inspect
        sig = inspect.signature(loading_data_fn)
        if len(sig.parameters) >= 2:
            _, test_set = loading_data_fn(args.data_root, args)
        else:
            _, test_set = loading_data_fn(args.data_root)
            
        print(f"âœ… {args.dataset_file} ê³µì‹ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì™„ë£Œ (ì´ë¯¸ì§€ {len(test_set)}ì¥)")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return
    
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë¡œë” (ë°°ì¹˜ ì‚¬ì´ì¦ˆ 1 ê³ ì •)
    data_loader_test = DataLoader(
        test_set, 1, shuffle=False, num_workers=args.num_workers,
        collate_fn=utils.collate_fn_crowd
    )

    # 4. ì„±ëŠ¥ í‰ê°€ (Evaluation on Test Set)
    print(f"ğŸ” [Step 4] ìµœì¢… í…ŒìŠ¤íŠ¸(Official Test) ì‹œì‘...")
    model.eval()
    start_time = time.time()
    
    with torch.no_grad():
        # engine.pyì˜ ê³µì‹ í‰ê°€ ë¡œì§ ì‚¬ìš© (ì—¬ê¸°ì„œ MAE, MSE ì‚°ì¶œ)
        mae, mse = evaluate_crowd_no_overlap(model, data_loader_test, device)
    
    end_time = time.time()
    
    # 5. ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥ ë° ì €ì¥
    result_text = f"""
========================================
ğŸ† {args.dataset_file} ê³µì‹ í…ŒìŠ¤íŠ¸(Test Set) ê²°ê³¼
========================================
- ê°€ì¤‘ì¹˜ íŒŒì¼: {args.weight_path}
- í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìˆ˜: {len(test_set)}
- MAE (ì •í™•ë„): {mae:.2f}
- MSE (ê°•ê±´ì„±): {mse:.2f}
- ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}s
========================================
"""
    print(result_text)
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    res_path = os.path.join(args.output_dir, f"official_test_res_{args.dataset_file}.txt")
    with open(res_path, "w") as f:
        f.write(result_text)
    print(f"ğŸ’¾ ê³µì‹ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {res_path}")

if __name__ == '__main__':
    parser = argparse.ArgumentParser('P2PNet official evaluation', parents=[get_args_parser()])
    args = parser.parse_args()
    main(args)